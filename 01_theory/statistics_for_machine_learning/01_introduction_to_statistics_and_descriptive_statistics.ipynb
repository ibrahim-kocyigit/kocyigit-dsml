{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Statistics and Descriptive Statistics\n",
    "\n",
    "---\n",
    "\n",
    "## 1. What is Statistics?\n",
    "Statistics is the science of collecting, organizing, analyzing, interpreting, and presenting data. It involves methods for drawing conclusions about populations based on samples. \n",
    "\n",
    "### 1.1. Why is Statistics Important for Machine Learning?\n",
    "Statistics plays a crucial role in machine learning in several ways:\n",
    "\n",
    "1. **Data Understanding (Exploratory Data Analysis - EDA):** Before building any machine learning model, it's essential to understand the data. Statistics provides tools for summarizing and visualizing data, identifying patterns, and detecting anomalies.\n",
    "\n",
    "2. **Data Preprocessing:** Machine learning models often require data to be in a specific format. Statistical techniques are used for tasks like:\n",
    "    * Handling missing values.\n",
    "    * Scaling and normalization.\n",
    "    * Feature engineering (creating new features from existing ones).\n",
    "\n",
    "3. **Model Evaluation:** Statistics provides methods for evaluating the performance of machine learning models, such as:\n",
    "    * Calculating accuracy, precision, recall, F1-score, etc.\n",
    "    * Using techniques like cross-validation.\n",
    "    * Performing hypothesis tests to compare different models.\n",
    "\n",
    "4. **Model Selection:** Statistical principles help in choosing the best model for a given problem and dataset. Concepts like the bias-variance tradeoff are fundamental to model selection.\n",
    "\n",
    "5. **Inference:** Statistics allows us to make inferences about populations based on sample data. This is important for generalizing the results of machine learning models to new, unseen data.\n",
    "\n",
    "6. **Algorithm Design:** Many machine learning models themselves are based in statistics.\n",
    "\n",
    "**In essence**, statistics provides the theoretical foundation and practical tools for working with data and building reliable machine learning models.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Measures of Central Tendency\n",
    "**Measures of central tendency** are statistical measures that describe a typical or central value in a dataset. These measures try to answer the question, _\"Where is the center of this dataset?\"_ or _\"What is the single value that best represents this data?\"_. Representing the center of a dataset with a single value helps us understand the general trend of the data, compare different datasets, and provide summary information.\n",
    "\n",
    "The most common measures of central tendency are the **mean**, **median**, and **mode**. \n",
    "\n",
    "### 2.1. Mean\n",
    "The **mean** is the value obtained by summing all the values in a dataset and dividing by the number of data points.\n",
    "\n",
    "If we have a dataset consisting of *n* values, $x_1, x_2, ..., x_n$, the mean (usually denoted by $\\bar{x}$ or $\\mu$) is calculated as:\n",
    "\n",
    "$\\bar{x} = \\frac{x_1 + x_2 + ... + x_n}{n} = \\frac{\\sum_{i=1}^{n} x_i}{n}$\n",
    "\n",
    "**Example:**  \n",
    "\n",
    "The mean of the dataset 2, 4, 6, 8, 10 is:\n",
    "\n",
    "$\\bar{x} = \\frac{2 + 4 + 6 + 8 + 10}{5} = \\frac{30}{5} = 6$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([2, 4, 6, 8, 10])\n",
    "mean_value = np.mean(data) # Calculating the mean\n",
    "\n",
    "print(\"Mean:\", mean_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Median\n",
    "The **median** is the middle value when a dataset is sorted. If the dataset has an odd number of values, the median is the middle value. If it has an even number of values, the median is the average of the two middle values.\n",
    "\n",
    "**Example:**\n",
    "*   2, 4, 6, 8, 10 (odd number of values): Median = 6\n",
    "*   2, 4, 6, 8 (even number of values): Median = (4 + 6) / 2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median (odd): 6.0\n",
      "Median (even): 5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data1 = np.array([2, 4, 6, 8, 10])\n",
    "data2 = np.array([2, 4, 6, 8])\n",
    "\n",
    "median_value1 = np.median(data1)\n",
    "median_value2 = np.median(data2)\n",
    "\n",
    "print(\"Median (odd):\", median_value1)\n",
    "print(\"Median (even):\", median_value2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Mode\n",
    "The **mode** is the value that appears most frequently in a dataset. A dataset can have multiple modes (bimodal, multimodal) or no mode at all.\n",
    "\n",
    "**Example:**  \n",
    "*   2, 4, 4, 6, 8: Mode = 4\n",
    "*   2, 4, 4, 6, 6, 8: Modes = 4 and 6 (bimodal)\n",
    "*   2, 4, 6, 8, 10: No mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: ModeResult(mode=np.int64(4), count=np.int64(2))\n",
      "Mode: ModeResult(mode=np.int64(4), count=np.int64(2))\n",
      "Mode: ModeResult(mode=np.int64(2), count=np.int64(1))\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats # Using the Scipy library\n",
    "\n",
    "data1 = np.array([2, 4, 4, 6, 8])\n",
    "data2 = np.array([2, 4, 4, 6, 6, 8])\n",
    "data3 = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "mode_value1 = stats.mode(data1)\n",
    "mode_value2 = stats.mode(data2)\n",
    "mode_value3 = stats.mode(data3)\n",
    "\n",
    "print(\"Mode:\", mode_value1)\n",
    "print(\"Mode:\", mode_value2)\n",
    "print(\"Mode:\", mode_value3)\n",
    "# the mode function returns the most repeated value and the number of times it is repeated.\n",
    "\n",
    "# ---- Note ----\n",
    "# The scipy.stats.mode() function returns only the *smallest* mode and its count if there are multiple modes.  If you need to find *all* modes, you would need a more advanced approach (e.g., using `collections.Counter` to count the occurrences of each value and then finding the maximum count).  But this is beyond the scope of this lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison of Mean, Median, and Mode: Choosing the Right Measure\n",
    "Choosing the appropriate measure of central tendency depends heavily on the distribution of your data and your specific analytical goals. We'll cover the selection of the appropriate measure of central tendency in detail in the \"Probability Distributions\" section (Lesson 3) later. For now, it's sufficient to know that the mean is sensitive to outliers, the median is more robust to outliers, and the mode represents the most frequent value.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Measures of Dispersion\n",
    "**Measures of dispersion** are statistical measures that indicate how spread out or variable the values in a dataset are. While measures of central tendency describe the \"center\" of the data, measures of dispersion show how much the data is \"scattered\" around this center. These measures answer questions like, _\"How spread out is the data?\"_ or _\"How different are the values from each other?\"_\n",
    "\n",
    "The most common measures of dispersion are **variance**, **standard deviation**, **range**, and **interquartile range (IQR)**.\n",
    "\n",
    "### 4.1. Variance\n",
    "**Variance** is the _average of the squared differences_ between each value in a dataset and the mean.\n",
    "\n",
    "If we have a dataset consisting of *n* values, $x_1, x_2, ..., x_n$, and the mean of this dataset is $\\bar{x}$, the variance (usually denoted by $s^2$ or $\\sigma^2$) is calculated as:\n",
    "\n",
    "*   **Sample Variance:** $s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}$ (Used when the dataset is assumed to be a *sample*. The *n-1* in the denominator ensures that the sample variance is an *unbiased* estimator of the population variance.)\n",
    "\n",
    "*   **Population Variance:** $\\sigma^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\mu)^2}{n}$ (Used when the dataset is assumed to represent the entire *population*. Here, $\\mu$ is the population mean.)\n",
    "\n",
    "**Example:**  \n",
    "Let's calculate the variance of the dataset 2, 4, 6, 8, 10 (as sample variance):\n",
    "\n",
    "1.  Mean: $\\bar{x} = 6$\n",
    "2.  Squared difference of each value from the mean:\n",
    "    *   $(2-6)^2 = 16$\n",
    "    *   $(4-6)^2 = 4$\n",
    "    *   $(6-6)^2 = 0$\n",
    "    *   $(8-6)^2 = 4$\n",
    "    *   $(10-6)^2 = 16$\n",
    "3.  Sum of these squares: $16 + 4 + 0 + 4 + 16 = 40$\n",
    "4.  Sample variance: $s^2 = \\frac{40}{5-1} = 10$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance: 10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "variance_value = np.var(data, ddof=1) # ddof=1 means Sample variance (n-1). If ddof=0 (default value), it would calculate the population variance\n",
    "\n",
    "print(\"Variance:\", variance_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Standard Deviation\n",
    "**Standard deviation** is the square root of the variance. It indicates how much the data typically spreads around the mean, expressed in the _original units of the dataset_.\n",
    "\n",
    "*   **Sample Standard Deviation:** $s = \\sqrt{s^2} = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}}$\n",
    "*   **Population Standard Deviation:** $\\sigma = \\sqrt{\\sigma^2} = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\mu)^2}{n}}$\n",
    "\n",
    "**Example:**  \n",
    "The standard deviation of the dataset in the previous example is:\n",
    "\n",
    "$s = \\sqrt{10} \\approx 3.16$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation: 3.1622776601683795\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "std_dev_value = np.std(data, ddof=1) # See the comment on the variance\n",
    "\n",
    "print(\"Standard Deviation:\", std_dev_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Range\n",
    "The **range** is the difference between the largest and smallest values in a dataset.\n",
    "\n",
    "$Range = max(x_i) - min(x_i)$\n",
    "\n",
    "**Example:**  \n",
    "The range for the dataset 2, 4, 6, 8, 10 is: $10 - 2 = 8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.array([2,4,6,8,10])\n",
    "range_value = np.max(data) - np.min(data)\n",
    "print(\"Range:\", range_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Interquartile Range\n",
    "The **interquartile range** is the difference between the _upper quartile (75th percentile, Q3)_ and the _lower quartile (25th percentile, Q1)_ of a dataset. It shows how spread out the middle 50% of the dataset is and is robust to outliers.\n",
    "\n",
    "$IQR = Q3 - Q1$\n",
    "\n",
    "* **Q1 (Lower Quartile):** The value that separates the bottom 25% of the data when sorted from smallest to largest.\n",
    "* **Q3 (Upper Quartile):** The value that separates the top 25% of the data (or the start of the bottom 75%) when sorted from smallest to largest.\n",
    "\n",
    "**Example:**   \n",
    "Suppose we have a dataset sorted from smallest to largest, and we find the quartiles as follows:  \n",
    "Q1 = 5, Q3 = 12  \n",
    "IQR = 12 - 5 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQR: 9.0\n",
      "IQR: 9.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20])\n",
    "\n",
    "q1 = np.percentile(data, 25)\n",
    "q3 = np.percentile(data, 75)\n",
    "iqr_value = q3 - q1\n",
    "print(\"IQR:\", iqr_value)\n",
    "\n",
    "# Alternatively\n",
    "from scipy import stats\n",
    "iqr_value2 = stats.iqr(data)\n",
    "print(\"IQR:\", iqr_value2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
