{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a785d2-8488-45f1-bb33-ad3d9a9baf1c",
   "metadata": {},
   "source": [
    "# Bayes' Theorem - A Spam Filter Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d64a2f-001d-4b91-b02f-af0f25be0938",
   "metadata": {},
   "source": [
    "Let's apply Bayes' theorem to another classic example: building a simple spam filter.\n",
    "\n",
    "**Scenario:**\n",
    "We have a dataset of 100 emails.\n",
    "* **20 emails are Spam.**\n",
    "* **80 emails are Not Spam** (often called \"Ham\").\n",
    "\n",
    "Without any other information, our best guess for a new email is that it has a 20% chance of being spam. This is our **prior probability**.\n",
    "\n",
    "To build a better model, we need to use features from the email's content. Let's analyze the presence of the word \"lottery\".\n",
    "\n",
    "**New Information (Our Evidence):**\n",
    "* Out of the 20 Spam emails, **14 contain the word \"lottery.\"**\n",
    "* Out of the 80 Ham emails, **10 contain the word \"lottery.\"**\n",
    "\n",
    "**The Core Question:**\n",
    "If we receive a *new* email that contains the word \"lottery,\" what is the probability that it is actually spam? In other words, we want to find **P(Spam | \"lottery\")**.\n",
    "\n",
    "---\n",
    "\n",
    "## The Intuitive Solution (Reducing the Sample Space)\n",
    "\n",
    "When we are given the evidence that an email contains the word \"lottery,\" our world shrinks. We no longer care about the emails that *don't* contain the word.\n",
    "\n",
    "1.  **Find the new sample space:** How many emails in total contain the word \"lottery\"?\n",
    "    * $14 (\\text{from spam}) + 10 (\\text{from ham}) = 24$ emails.  \n",
    "` `\n",
    "2.  **Find the number of favorable outcomes:** Within this new sample space of 24 emails, how many are actually spam?\n",
    "    * **14** emails.  \n",
    "` `\n",
    "3.  **Calculate the probability:**\n",
    "    $$ P(\\text{Spam} | \\text{\"lottery\"}) = \\frac{\\text{Number of spam emails with \"lottery\"}}{\\text{Total number of emails with \"lottery\"}} = \\frac{14}{24} = \\frac{7}{12} \\approx 0.583 $$\n",
    "\n",
    "So, after seeing the word \"lottery,\" our belief that the email is spam has increased from our prior probability of 20% to a new **posterior probability** of 58.3%.\n",
    "\n",
    "This process of updating our belief based on new evidence is exactly what Bayes' theorem formalizes.\n",
    "\n",
    "---\n",
    "## The Formal Solution (Using Bayes' Theorem)\n",
    "\n",
    "Let's solve the same problem using the formula.\n",
    "\n",
    "**Events:**\n",
    "* **A:** The email is Spam.\n",
    "* **B:** The email contains the word \"lottery\".\n",
    "\n",
    "**Bayes' Theorem:**\n",
    "$$ P(A|B) = \\frac{P(A) \\cdot P(B|A)}{P(A) \\cdot P(B|A) + P(A') \\cdot P(B|A')} $$\n",
    "\n",
    "Let's calculate each component from our initial data:\n",
    "* **$P(A)$ (Prior):** The overall probability of an email being spam.\n",
    "    * $P(\\text{Spam}) = \\frac{20}{100} = 0.2$  \n",
    "` `\n",
    "* **$P(A')$ (Complement):** The overall probability of an email being ham.\n",
    "    * $P(\\text{Not Spam}) = \\frac{80}{100} = 0.8$  \n",
    "` `\n",
    "* **$P(B|A)$ (Likelihood):** The probability of seeing the word \"lottery\" *given that* the email is spam.\n",
    "    * Out of 20 spam emails, 14 have the word. $P(\\text{\"lottery\"}| \\text{Spam}) = \\frac{14}{20} = 0.7$  \n",
    "` `\n",
    "* **$P(B|A')$ (Likelihood of Complement):** The probability of seeing the word \"lottery\" *given that* the email is ham.\n",
    "    * Out of 80 ham emails, 10 have the word. $P(\\text{\"lottery\"}| \\text{Not Spam}) = \\frac{10}{80} = 0.125$\n",
    "\n",
    "Now, we plug these values into the formula:\n",
    "$$ P(\\text{Spam} | \\text{\"lottery\"}) = \\frac{(0.2) \\cdot (0.7)}{(0.2) \\cdot (0.7) + (0.8) \\cdot (0.125)} $$\n",
    "$$ = \\frac{0.14}{0.14 + 0.1} = \\frac{0.14}{0.24} \\approx 0.583 $$\n",
    "\n",
    "The formal calculation gives us the exact same result as our intuitive method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
