{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e663464b-e252-4e99-afc9-3436baa87e80",
   "metadata": {},
   "source": [
    "# Regression with a Perceptron: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a5bead-639a-448a-80f4-b5ece3b4e892",
   "metadata": {},
   "source": [
    "In this module, you're going to learn what a neural network is and how to train one using gradient descent. The fundamental unit of a neural network is the **perceptron**. This may sound like a new concept, but you've already seen one, because **linear regression** can be expressed as a perceptron.\n",
    "\n",
    "Let's use one of the most classic examples in linear regression: predicting the price of a house.\n",
    "\n",
    "We start with a dataset. For each house, we have a feature (its size) and a target (its price).\n",
    "* **Feature:** `size_sqft`\n",
    "* **Target:** `price_usd`\n",
    "\n",
    "If we plot this data, we might see a linear trend. The goal of linear regression is to find the \"line of best fit\" that captures this trend and allows us to predict the price for a new house given its size.\n",
    "\n",
    "![](./images/0101.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d58f4e-d91f-4c74-bce1-751c5f7c0257",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## From One Feature to Many: The Perceptron Model\n",
    "\n",
    "In the real world, the price of a house depends on more than just its size. Let's add a second feature: the **number of rooms**.\n",
    "\n",
    "How can we combine both `size` and `rooms` to make a better prediction? A simple line is no longer enough. We need a more general model that can handle any number of inputs. This is the **perceptron**.\n",
    "\n",
    "A perceptron is the simplest possible neural network. It's a model designed to take multiple inputs, combine them, and produce a single output.\n",
    "\n",
    "![](./images/0102.png)\n",
    "\n",
    "Let's break down how it works step-by-step:\n",
    "\n",
    "* **Inputs (Features):** These are the known characteristics of our house. \n",
    "    * $x_1$: size_sqft  \n",
    "\n",
    "    * $x_2$: number_of_rooms  \n",
    "\n",
    "* **Weights (Parameters):** Each input feature is multiplied by a corresponding **weight**. The weight represents the importance of that feature. A feature that has a large impact on the price will learn a large weight.\n",
    "    * $w_1$: weight for size  \n",
    "\n",
    "    * $w_2$: weight for rooms\n",
    "\n",
    "* **Bias (Parameter):** A constant value, `b`, is also added. The bias represents a baseline price and allows the model to fit data that doesn't pass through the origin. For example, a house has some base value even if its size and room count were zero.\n",
    "\n",
    "* **Summation:** The perceptron calculates the **weighted sum** of the inputs and adds the bias.\n",
    "\n",
    "The final output, $\\hat{y}$ (our predicted price), is given by the familiar linear equation:\n",
    "$$ \\hat{y} = w_1x_1 + w_2x_2 + b $$\n",
    "\n",
    "This equation describes a **plane** in 3D space, which is the higher-dimensional equivalent of our 2D line of best fit. The \"learning\" task for this model is to find the optimal values for the **parameters**—the weights ($w_1, w_2$) and the bias (`b`)—that make our predictions as close as possible to the actual prices for every house in our dataset.\n",
    "\n",
    "To do this, we first need a way to measure the total \"error\" of our model. This is the job of a **loss function**, which we will explore next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
