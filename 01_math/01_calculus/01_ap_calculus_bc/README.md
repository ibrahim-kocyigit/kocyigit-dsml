## AP®︎ Calculus BC
This section covers the full scope of single-variable calculus, corresponding to the AP®︎ Calculus BC curriculum. It delves into the foundational concepts of limits, derivatives, and integrals, which are indispensable for machine learning.

Derivatives form the basis of the optimization algorithms that train nearly all modern ML models, most notably Gradient Descent and the backpropagation algorithm used in neural networks. Integrals are essential for working with continuous probability distributions, and the study of infinite series provides the tools to approximate complex functions.

The notes in this section are curated from my studies of the [AP Calculus BC](https://www.khanacademy.org/math/ap-calculus-bc) course on [Khan Academy](https://www.khanacademy.org/).