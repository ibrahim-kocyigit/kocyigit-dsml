{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d908687-004c-4536-8471-5f129a4b53f6",
   "metadata": {},
   "source": [
    "# Covariance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac0380-0b4e-4b1e-83fc-7ed91e6f15d6",
   "metadata": {},
   "source": [
    "We've learned about variance (how a single variable is spread out) and covariance (how two variables change together). The **covariance matrix** is a powerful tool that neatly organizes all these measures into a single grid.\n",
    "\n",
    "It provides a complete summary of the relationships between all pairs of variables in your dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## Motivating the Covariance Matrix\n",
    "\n",
    "Consider the three datasets below. If we were to calculate the variance for each, we would find that the x-variance and y-variance are roughly the same for all three plots. However, it's clear that the underlying relationships are completely different.\n",
    "\n",
    "This is where the covariance matrix shines. It captures not only the individual spread of each variable but also the direction of their relationship.\n",
    "\n",
    "![Covariance Example](./images/0401.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Constructing the Covariance Matrix\n",
    "\n",
    "For a dataset with two variables, `x` and `y`, the covariance matrix `C` is a 2x2 matrix built as follows:\n",
    "\n",
    "1.  **Calculate the components:**\n",
    "    * Variance of x: $\\text{Var}(x)$\n",
    "    * Variance of y: $\\text{Var}(y)$\n",
    "    * Covariance of x and y: $\\text{Cov}(x, y)$  \n",
    "` `\n",
    "2.  **Build the matrix:**  \n",
    "\n",
    "    $\n",
    "    C = \\begin{bmatrix}\n",
    "    \\text{Var}(x) & \\text{Cov}(x, y) \\\\\n",
    "    \\text{Cov}(y, x) & \\text{Var}(y)\n",
    "    \\end{bmatrix}\n",
    "    $\n",
    "\n",
    "A key property is that the matrix is **symmetric**, meaning $\\text{Cov}(x, y) = \\text{Cov}(y, x)$.\n",
    "\n",
    "Furthermore, the variance of a variable with itself is just its variance ($\\text{Var}(x) = \\text{Cov}(x, x)$). This means we can think of the covariance matrix as a generalized grid of covariances:  \n",
    "\n",
    "$\n",
    "C = \\begin{bmatrix}\n",
    "\\text{Cov}(x, x) & \\text{Cov}(x, y) \\\\\n",
    "\\text{Cov}(y, x) & \\text{Cov}(y, y)\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "## The Matrix Notation Formula\n",
    "\n",
    "While we can calculate each component individually, there is a very efficient and elegant way to compute the entire covariance matrix at once using matrix operations.\n",
    "\n",
    "Given a data matrix `A` with `n` rows (observations) and `c` columns (features):\n",
    "\n",
    "1.  **Center the data:** Calculate the mean of each column and subtract it from every element in that column. Let's call this centered matrix `A_centered`.\n",
    "2.  **Calculate the product:** The covariance matrix `C` is then given by the formula:  \n",
    "\n",
    "    $ C = \\frac{1}{n-1} A_{centered}^T \\cdot A_{centered} $\n",
    "\n",
    "![Covariance Matrix](./images/0402.png)\n",
    "\n",
    "Note that this matrix multiplication gives us the values of the 2x2 covariance matrix, because the dot products of the rows of the first matrix and the columns of the second matrix are the actual formulas of the 4 values of the matrix $\n",
    "    \\begin{bmatrix}\n",
    "    \\text{Var}(x) & \\text{Cov}(x, y) \\\\\n",
    "    \\text{Cov}(y, x) & \\text{Var}(y)\n",
    "    \\end{bmatrix}\n",
    "    $\n",
    "\n",
    "---\n",
    "\n",
    "## A Worked Example\n",
    "\n",
    "Let's walk through this with a real example.\n",
    "\n",
    "![Worked Example](./images/0403.png)\n",
    "\n",
    "1. First, we write our data on a table of two columns, one for each feature.\n",
    "2. Then we calculate the mean of each column:  \n",
    "* $\\mu_x = 8$\n",
    "* $\\mu_y = 6$\n",
    "\n",
    "3. Then we center the data by subtracting the mean from each column.\n",
    "4. Then we we transpose the centered matrix.\n",
    "5. Finally we perform the matrix multiplication and scale.\n",
    "\n",
    "The result of this calculation is the final 2x2 covariance matrix for our dataset. \n",
    "\n",
    "\n",
    "\n",
    "This process extends to any number of features; a dataset with 3 features would produce a 3x3 covariance matrix, and so on. This matrix operation is a fundamental building block for PCA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
