{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b02912-6b31-47da-941c-a99bf56e0730",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction and Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4edae3b-f09f-4667-afcf-68ca52746ecc",
   "metadata": {},
   "source": [
    "The final major topic of this course is **Principal Component Analysis (PCA)**. The goal of PCA is to reduce the number of columns (the dimensions) of a dataset while preserving as much of the original information as possible. In short, PCA makes a dataset \"skinnier\" by intelligently combining features.\n",
    "\n",
    "### Why Reduce Dimensions?\n",
    "1.  **Manageability:** Real-world datasets can have hundreds or thousands of features. Reducing the number of columns makes the data easier to work with, store, and model.\n",
    "2.  **Visualization:** It's impossible to visualize data in more than three dimensions. By reducing a high-dimensional dataset to just two or three \"principal components,\" we can create meaningful scatter plots to look for patterns.\n",
    "\n",
    "Simply deleting columns is a bad approach because we lose all the valuable information they contained. PCA is designed to address this by **projecting** the data into a lower-dimensional space in a way that retains the most important information.\n",
    "\n",
    "---\n",
    "## The Concept of Projection\n",
    "\n",
    "Projection is the process of moving data points from a higher-dimensional space onto a lower-dimensional one (like a line or a plane).\n",
    "\n",
    "Imagine we have a simple 2D dataset and we want to project it onto the line defined by the equation `y = x`. This means we want to find the \"shadow\" that each point casts on that line.\n",
    "\n",
    "![](./images/0101.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab00bc-9429-46bc-bf00-f79a2dbb02e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Math of Projection\n",
    "\n",
    "How do we calculate the location of these new, projected points? The process uses the dot product and the norm.\n",
    "\n",
    "To project a matrix of data `A` onto the direction given by a vector `v`, we use the following formula:\n",
    "\n",
    "$ A_{proj} = A \\cdot \\frac{v}{||v||_2} $\n",
    "\n",
    "Let's break this down:\n",
    "1.  **Normalize the Direction Vector:** We first divide the vector `v` by its L2-norm (`||v||_2`). This creates a **unit vector** that points in the same direction but has a length of 1. This is crucial because it ensures our projection only changes the position of the points, not their scale.\n",
    "2.  **Take the Dot Product:** We then take the dot product of our data matrix `A` with this new unit vector. This calculates the new, 1-dimensional coordinates for each of our data points along the projection line.\n",
    "\n",
    "For our 2D data and the projection line `y=x` (defined by the vector `v = [1, 1]`), we have successfully reduced our dataset from a table with **two columns** (x and y coordinates) to a single vector with **one column** (the distance along the line).\n",
    "\n",
    "---\n",
    "## Generalizing the Projection\n",
    "\n",
    "We can project our data onto multiple vectors at once. Projecting onto two vectors is the same as projecting onto the **plane** that those vectors span.\n",
    "\n",
    "To do this, we simply create a matrix `V` where each column is one of our (normalized) direction vectors. The final projection formula is an elegant matrix multiplication:\n",
    "\n",
    "> $ A_p = A \\cdot V $\n",
    "\n",
    "* If `A` is an `r x c` matrix (r rows, c columns)\n",
    "* And `V` is a `c x k` matrix (c rows, k new dimensions)\n",
    "* The resulting projected matrix `A_p` will be `r x k`.\n",
    "\n",
    "The data now has the same number of rows but has been reduced from `c` dimensions to `k` dimensions.\n",
    "\n",
    "The key question now is: how do we pick the best vectors or the best line to project onto? That is what PCA will help us determine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
